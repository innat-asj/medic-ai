{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":6578801,"sourceType":"datasetVersion","datasetId":3798960}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import logging\nlogging.disable(logging.WARNING)\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport pprint","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sample Overview","metadata":{}},{"cell_type":"code","source":"import json\nimport nibabel as nib\n\nimg_path = '/kaggle/input/abdomen/imagesTr/img0001.nii'\nmask_path = '/kaggle/input/abdomen/labelsTr/label0001.nii'\ntest_image_nib = nib.load(img_path)\ntest_mask_nib = nib.load(mask_path)\n\ntest_image_nib.shape, test_mask_nib.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ntest_image = np.transpose(test_image_nib.get_fdata(), (2, 1, 0))[:, -1::-1, -1::-1]\ntest_mask = np.transpose(test_mask_nib.get_fdata(), (2, 1, 0))[:, -1::-1, -1::-1]\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\nax1.imshow(test_image[test_image.shape[0]//2], cmap='gray')\nax1.set_title(f'Image shape: {test_image.shape}')\nax2.imshow(test_mask[test_mask.shape[0]//2])\nax2.set_title(f'Label shape: {test_mask.shape}')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from skimage.util import montage\n\nfig, ax1 = plt.subplots(1, 1, figsize = (20, 20))\nax1.imshow(montage(test_image, padding_width=10, fill=1), cmap='gray')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (20, 20))\nax1.imshow(montage(test_mask, padding_width=10, fill=1))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"with open('/kaggle/input/abdomen/dataset_0.json') as f:\n    dataset_json = json.load(f)\n\nprint(dataset_json.keys())\npprint.pprint(dataset_json)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# TFRecord Creation","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef serialize_example(image_path, label_path):\n    image_path = os.path.join('/kaggle/input/abdomen', image_path)\n    label_path = os.path.join('/kaggle/input/abdomen', label_path)\n\n    image_nii = nib.load(image_path)\n    label_nii = nib.load(label_path)\n\n    image = image_nii.get_fdata().astype(np.float32)\n    label = label_nii.get_fdata().astype(np.float32)\n    image_shape = np.array(image.shape, dtype=np.int64)\n    label_shape = np.array(label.shape, dtype=np.int64)\n    image_raw = image.tobytes()\n    label_raw = label.tobytes()\n\n    image_affine = image_nii.affine\n    label_affine = label_nii.affine\n    image_header = image_nii.header\n    label_header = label_nii.header\n    image_pixdim = np.array(image_header['pixdim'], dtype=np.float32)\n    label_pixdim = np.array(label_header['pixdim'], dtype=np.float32)\n    \n    feature = {\n        \"image_raw\": tf.train.Feature(\n            bytes_list=tf.train.BytesList(value=[image_raw])\n        ),\n        \"label_raw\": tf.train.Feature(\n            bytes_list=tf.train.BytesList(value=[label_raw])\n        ),\n        \"image_shape\": tf.train.Feature(\n            int64_list=tf.train.Int64List(value=image_shape)\n        ),\n        \"label_shape\": tf.train.Feature(\n            int64_list=tf.train.Int64List(value=label_shape)\n        ),\n        \"image_affine\": tf.train.Feature(\n            float_list=tf.train.FloatList(value=image_affine.flatten())\n        ),\n        \"label_affine\": tf.train.Feature(\n            float_list=tf.train.FloatList(value=label_affine.flatten())\n        ),\n        \"image_pixdim\": tf.train.Feature(\n            float_list=tf.train.FloatList(value=image_pixdim.flatten())\n        ),\n        \"label_pixdim\": tf.train.Feature(\n            float_list=tf.train.FloatList(value=label_pixdim.flatten())\n        ),\n    }\n    example = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example.SerializeToString()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\noutput_dir = \"tfrecords\"\nos.makedirs(output_dir, exist_ok=True)\n\ndef create_tfrec(dataset, shard_size=3, set='training'):\n    num_shards = (len(dataset) + shard_size - 1) // shard_size\n    \n    for shard_idx in range(num_shards):\n        shard_path = os.path.join(output_dir, f\"{set}_shard_{shard_idx}.tfrec\")\n        start_idx = shard_idx * shard_size\n        end_idx = min(start_idx + shard_size, len(dataset))\n    \n        with tf.io.TFRecordWriter(shard_path) as writer:\n            for i in tqdm(\n                range(start_idx, end_idx), \n                desc=f\"Writing Shard {shard_idx}/{num_shards-1}\"\n            ):\n                sample = dataset[i]\n                tf_example = serialize_example(sample[\"image\"], sample[\"label\"])\n                writer.write(tf_example)\n    \n        print(f\"Shard {shard_idx} for {set} saved: {shard_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"create_tfrec(dataset_json[\"training\"], shard_size=10, set='training')\ncreate_tfrec(dataset_json[\"validation\"], shard_size=10, set='validation')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def parse_tfrecord_fn(example_proto):\n    feature_description = {\n        \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n        \"label_raw\": tf.io.FixedLenFeature([], tf.string),\n        \"image_shape\": tf.io.FixedLenFeature([3], tf.int64),\n        \"label_shape\": tf.io.FixedLenFeature([3], tf.int64),\n        \"image_affine\": tf.io.FixedLenFeature([16], tf.float32),\n        \"label_affine\": tf.io.FixedLenFeature([16], tf.float32),\n        \"image_pixdim\": tf.io.FixedLenFeature([8], tf.float32),\n        \"label_pixdim\": tf.io.FixedLenFeature([8], tf.float32),\n    }\n    \n    example = tf.io.parse_single_example(example_proto, feature_description)\n    \n    # Decode image and label data\n    image = tf.io.decode_raw(example[\"image_raw\"], tf.float32)\n    label = tf.io.decode_raw(example[\"label_raw\"], tf.float32)\n    \n    # Reshape to original dimensions\n    image = tf.reshape(image, example[\"image_shape\"])\n    label = tf.reshape(label, example[\"label_shape\"])\n    \n    # Decode affine matrices\n    image_affine = tf.reshape(example[\"image_affine\"], (4, 4))\n    label_affine = tf.reshape(example[\"label_affine\"], (4, 4))\n    \n    # Decode voxel spacing (pixdim)\n    image_pixdim = example[\"image_pixdim\"]\n    label_pixdim = example[\"label_pixdim\"]\n\n    return image, label, image_affine, label_affine, image_pixdim, label_pixdim","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tfrecord_path = \"tfrecords/training_shard_0.tfrec\"\ndataset = tf.data.TFRecordDataset(tfrecord_path)\ndataset = dataset.map(parse_tfrecord_fn)\n\nfor image, label, image_affine, label_affine, image_pixdim, label_pixdim in dataset:\n    print(\"Image shape:\", image.shape)\n    print(\"Label shape:\", label.shape)\n    print(\"Image affine matrix:\", image_affine.numpy())\n    print(\"Label affine matrix:\", label_affine.numpy())\n    print(\"Image voxel spacing:\", image_pixdim.numpy())\n    print(\"Label voxel spacing:\", label_pixdim.numpy())\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load","metadata":{}},{"cell_type":"code","source":"def parse_tfrecord_fn(example):\n    feature_description = {\n        \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n        \"label_raw\": tf.io.FixedLenFeature([], tf.string),\n        \"image_shape\": tf.io.FixedLenFeature([3], tf.int64),\n        \"label_shape\": tf.io.FixedLenFeature([3], tf.int64),\n    }\n    parsed_example = tf.io.parse_single_example(example, feature_description)\n    image = tf.io.decode_raw(parsed_example[\"image_raw\"], tf.float32)\n    label = tf.io.decode_raw(parsed_example[\"label_raw\"], tf.float32)\n    image_shape = tf.cast(parsed_example[\"image_shape\"], tf.int64)\n    label_shape = tf.cast(parsed_example[\"label_shape\"], tf.int64)\n    image = tf.reshape(image, image_shape)\n    label = tf.reshape(label, label_shape)\n    return image, label","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_tfrecord_dataset(tfrecord_pattern, batch_size=1):\n    dataset = tf.data.TFRecordDataset(tf.io.gfile.glob(tfrecord_pattern))\n    dataset = dataset.map(parse_tfrecord_fn, num_parallel_calls=tf.data.AUTOTUNE)\n    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset\n\ntfrecord_pattern = \"tfrecords/{}_shard_*.tfrec\"\ntrain_ds = load_tfrecord_dataset(tfrecord_pattern.format(\"training\"), batch_size=1)\nval_ds = load_tfrecord_dataset(tfrecord_pattern.format(\"validation\"), batch_size=1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x, y = next(iter(train_ds))\nx.shape, y.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x, y = next(iter(val_ds))\nx.shape, y.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"x_temp = x.numpy().squeeze()\ny_temp = y.numpy().squeeze()\nx_temp.shape, y_temp.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_image = np.transpose(x_temp, (2, 1, 0))[:, -1::-1, -1::-1]\ntest_mask = np.transpose(y_temp, (2, 1, 0))[:, -1::-1, -1::-1]\nprint(np.unique(test_mask))\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\nax1.imshow(test_image[test_image.shape[0]//2], cmap='gray')\nax1.set_title(f'Image shape: {test_image.shape}')\nax2.imshow(test_mask[test_mask.shape[0]//2])\nax2.set_title(f'Label shape: {test_mask.shape}')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fig, ax1 = plt.subplots(1, 1, figsize = (20, 20))\nax1.imshow(montage(test_mask, padding_width=10, fill=1))\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}